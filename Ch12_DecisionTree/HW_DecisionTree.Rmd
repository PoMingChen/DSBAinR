---
title: "HW_DecisionTree"
author: "PoMingChen"
date: "8/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 說明

在這個章節的作業中，我們同樣使用「航空顧客忠誠度」及「餐飲營收預測」的資料集實作決策樹分析，完成個案中尚未嘗試的模型，並提供適當的決策建議。

## 注意事項

- 設置工作路徑，並確定兩個資料集合都放置在你的工作路徑：

- 讀成data.frame
`read.csv('檔案名稱', encoding = 'UTF-8')`
- 讀成tibble
`read_csv('檔案名稱', locale= locale(encoding='UTF-8'))`

## Env Setting 

```{r}
library(tidyverse)
library(magrittr)
library(plotROC)
library(rpart)
library(rpart.plot)
```


```{r}
internal.data <- read_csv("./航空業分析資料集/internal_data.csv", locale = locale(encoding = "UTF-8"))

survey.data <- read_csv("./航空業分析資料集/survey_data.csv", locale = locale(encoding = "UTF-8"))
```

```{r}
internal.data %>% colnames()
survey.data %>% colnames()
```


```{r}
sales.data.renew <- read_csv("./餐飲業分析資料集/Restaurant_Sales_Renew.csv", locale = locale(encoding = "UTF-8"))
```

#### kind reminder

在決策樹模型裡面，一共有分類樹以及數值樹兩種方式。

分類樹與Logistic比較接近，因此若原始資料正確，其實模型可以疏途同歸，但是衡量模型良窳的方式就必須一致，使用ROC Curve and AUC, Area under the curve.

數值樹與LM比較接近，因此若原始資料正確，其實模型可以疏途同歸，但是衡量模型良窳的方式就必須一致，使用RMSE, Root mean square error，或者是MAPE, mean absolute value percentage error.

## 題目一

#### Data Transformation

```{r}
internal.data %>% colnames()
```

```{r}
internal.data$credit_card_vendor <- as.factor(internal.data$credit_card_vendor)
internal.data$credit_card_bonus <- as.factor(internal.data$credit_card_bonus)
```

```{r}
survey.data %>% colnames()
```

```{r}
survey.data$register_method <- as.factor(survey.data$register_method)
survey.data$class <- as.factor(survey.data$class)
survey.data$is_loyal <- ifelse(survey.data$is_loyal==1, "Satisified", "Unsatisified")
```

```{r}
complete.data <- internal.data %>% merge(x=., y=survey.data, by = "user_id")
```

```{r}
complete.data %>% head()
complete.data %>% colnames()
```

```{r}
complete.data %<>% select(1,8,everything())
```

#### 進入題目

1. 建立僅包含「服務品質」的資料集：共有depart_on_time、arrive_on_time、register_method、register_rate、class、seat_rate、meal_rate、flight_rate、package_rate等變數。

```{r}
survey.model <- rpart(is_loyal~depart_on_time+
                               arrive_on_time+
                               register_method+
                               register_rate+
                               class+
                               seat_rate+
                               meal_rate+
                               flight_rate+
                               package_rate,
                               data = survey.data,
                               cp = 0.01, #cp = 0.01 is the default
                               parms = list(split='information')) #The splitting index can be gini or information. The default priors are proportional to the data counts, the losses default to 1, and the split defaults to gini.
```

2. 決策樹分析：建立CART分類樹模型，並使用Entropy當作分類指標，並計算AUC。

```{r}
rpart.plot(survey.model)
```

```{r}
#object, a **model object** for which prediction is desired. (所以前面必定是放你設計的model，不定參數放你original 的data)
predict.prob <- predict(object = survey.model, survey.data)[,2] 
```

```{r Use survey.model and complete. data}
predict.prob.table <- tibble(
  true_label = survey.data$is_loyal,
  predict.prob.of.Unsatisified = predict(object = survey.model, survey.data)[,2] 
)
predict.prob.table %>% head()
``` 

```{r Use survey.model and complete.data}
#Bad example, but good concept review.

#The prediction of complete.data into survey.model is really bad. It's simple to understand it through the LogOdd linear regression on the variables. With only few variable(X_1~X_i not to X_j), that's not really fitted.

predict.prob.table.test <- tibble(
    true_label = survey.data$is_loyal,
    predict.prob.of.Unsatisified = predict(object = survey.model, complete.data)[,2] 
)

predict.prob.table.test %>% head()
```

```{r}
predict.prob.table %>% ggplot(data =., aes(d=true_label, m=predict.prob.of.Unsatisified)) + geom_roc(n.cuts = 3, labelsize = 3, labelround = 2) -> predict.prob.table.ROCgraph
```

```{r}
predict.prob.table.ROCgraph + style_roc(xlab = "1-Specificity", ylab = "sensitivity") + annotate(geom = "text",                                                              x=0.75, 
                          y=0.25,
                          label = paste0("AUC=", as.character(
                          round(calc_auc(predict.prob.table.ROCgraph
                                                 )$AUC, digits = 3)
                          ))
                                        )
```


3. 決策樹視覺化：試著從視覺化結果提出決策建議，可以自行決定剪枝，以提供更好的洞見。

目前看起來決策樹分類結果有三個重點：

1. `seat_rate>=3`座艙滿意率是影響顧客忠誠度的最大因素
2. `depart_on_time=1` `arrive_on_time=1`在決策樹分類上有差不多的重要程度。也就是準點與否，也會一定程度的影響
3. 最次之的則是`meal_rate>4`餐點滿意度，以及`register_rate<2`註冊為會員時候的使用介面友善度

只考慮「服務品質」的模型，一共用了九個變數。目前看起來顧客最在意航班的舒適度（是否能夠充分休息，或至少不消耗精神），接來是準時與否也是重要的。甚至就算`seat_rate>=3`沒有被滿足，後續的`arrive_on_time=1`若顧客的航班是準點，以及`seat_rate>=2`，最終也一樣顧客會對我們有忠誠度。

因此我們甚至可以說，`seat_rate`和`"Be"_on_time`這兩個條件可以說絕對不可失分的兩個因素。本質上顧客最在意航班這個交通方式是否是個「放心與能夠休息，勝過於追求過程中的享受」的交通選擇，何況`meal_rate>4`算是一個高門檻，消費者必須要覺得很好吃才有可能變得忠誠。何況他還只是次要因素。

想要挖掘更多的內容，所以希望可以讓決策樹開枝散葉，用`cp=0.005`試看看

後來我們發現`cp=0.005`的決策樹與一開始的`cp=0.01`並無不同。當`cp=0.04`才出現改變，但最終AUC = 0.769 > 0.764。顯示出目前的分類樹模型已經相當穩定，給stakeholder的建議可以集中在座艙的舒適度提升，以及航班的準點，就可以獲得相當多客戶青睞。

```{r}
rpart.plot(survey.model)
```

```{r}
survey.tune.model <- rpart(is_loyal~depart_on_time+
                               arrive_on_time+
                               register_method+
                               register_rate+
                               class+
                               seat_rate+
                               meal_rate+
                               flight_rate+
                               package_rate,
                               data = survey.data,
                               cp = 0.004, #cp = 0.01 is the default
                               parms = list(split='information')) 
```

```{r}
rpart.plot(survey.tune.model)
```

```{r}
#object, a **model object** for which prediction is desired. (所以前面必定是放你設計的model，不定參數放你original 的data)
predict.tune.prob <- predict(object = survey.tune.model, survey.data)[,2] 
```

```{r Use survey.model and complete. data}
predict.tune.prob.table <- tibble(
  true_label = survey.data$is_loyal,
  predict.tune.prob.of.Unsatisified = predict(object = survey.tune.model, survey.data)[,2] 
)
``` 

```{r}
predict.tune.prob.table %>% ggplot(data =., aes(d=true_label, m=predict.tune.prob.of.Unsatisified)) + geom_roc(n.cuts = 3, labelsize = 3, labelround = 2) -> predict.tune.prob.table.ROCgraph
```

```{r}
predict.tune.prob.table.ROCgraph + style_roc(xlab = "1-Specificity", ylab = "sensitivity") + annotate(geom = "text",                                                              x=0.75, 
                          y=0.25,
                          label = paste0("AUC=", as.character(
                          round(calc_auc(predict.tune.prob.table.ROCgraph
                                                 )$AUC, digits = 3)
                          ))
                                        )
```


## 題目二

1. 建立僅包含RegionA的資料集

> RegionA，包含Store1 4

```{r}
sales.data.renew %>% filter(Region %in% "A") -> sales.data.renew.A
```

```{r}
sales.data.renew.A %>%
  colnames()
```

2. 決策樹分析：建立CART迴歸樹模型，並利用MAPE衡量分類結果。

```{r}
Model.A <- rpart(Sales ~ .,
                 data = sales.data.renew.A, 
                 cp = 0.005,
                 parms = list("Information"))
```

```{r}
rpart.plot(Model.A)
```

```{r}
#MAPE, mean absolute percentage error
MAPE.function <- function(prediction, actual) {
  mean(abs((prediction-actual)/actual)) -> decimal
  decimal %<>% round(., digits = 4)
  paste0(as.character(decimal*100), "%") -> MAPE
  print(MAPE)
}
```

```{r}
pred.sales <- predict(Model.A, sales.data.renew.A)
pred.sales
```

```{r}
cat("Model.A MAPE: \n", MAPE.function(pred.sales, sales.data.renew.A$Sales), sep = "")
```

3. 決策樹視覺化：試著從視覺化結果提出決策建議，可以自行決定剪枝，以提供更好的洞見。

RegionA本身是觀光區，包含了Store1, Store4。店面類型（Type）主要包含`百貨門市AA Store1`，以及`獨立門市BB Store4`。

1. 影響營收最大的因素在於`店面類型`，很明顯地是`百貨門市`的話，預估營收會比`獨立門市`高。
2. 第二重要影響營收的因素則是`Weekday`，平日或者假日。很明顯地是`假日`的時候預估營收會比`平日`來得高。
3. 第三重要影響因素則是淡旺季的月份

- Store1本身`TypeBB = No`，他是百貨門市。淡季主要是三、四、六、八、十一月
- Store4本身`TypeBB = Yes`，他是獨立門市。淡季主要是二、三、四、五、六、九、十、十一月

若我是店長，我應該會想要知道，關於影響Store1, Store4，除了`店面類型`，`平假日`，`淡旺季`因素以外（因為這三項其實滿僵固的，不見得是我一位店長就能夠改變什麼的，今天若就是假日，資源準備多一點是做生意的基本），有哪些更細微屬於該店面特殊的影響因素，是我可以控制或者因應的呢？

所以商業問題，這時候會想要將決策樹開枝散葉，看看更細微的影響因素。

```{r}
rpart.plot(Model.A)
```

那將`cp = 0.005`調整為`cp = 0.004`則會發現屬於百貨門市的 __Store1__，其`Store_Event`的影響力也被凸顯出來。反而獨立門市的 __Store4__決策樹分支一直很穩定，直到`cp=0.0025`時候才會在分叉，但是已經有出現Over-fitting的問題。因此不予考慮。

當決策樹模型調整為`cp = 0.004`，MAPE = 7.67% < 8.28 in `cp = 0.005`，模型預測效率有再改善一些。

所以若是RegionA這兩家店的店長，除了`店面類型`，`平假日`，`淡旺季`因素以外，我也會多加留意Store1的週年慶期間，店內的人力物力資源配置。

```{r}
tune.Model.A <- rpart(Sales ~ .,
                      data = sales.data.renew.A,
                      cp = 0.004,
                      parms = list("Information"))
```

```{r}
rpart.plot(tune.Model.A)
```

```{r}
tune.pred.sales <- predict(tune.Model.A, sales.data.renew.A)
tune.pred.sales
```

```{r}
cat("Model.A MAPE: \n", MAPE.function(tune.pred.sales, sales.data.renew.A$Sales), sep = "")
```

